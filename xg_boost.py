# -*- coding: utf-8 -*-
"""xg_boost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t_I_9pF8gd6knhH6UPTS6GTYVk3xGOl8

# XGBoost

## Importing the libraries
"""

import numpy as np                                #importing libraries.
import matplotlib.pyplot as plt
import pandas as pd

"""## Importing the dataset"""

dataset = pd.read_csv('Data.csv')                #importing the dataset.
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

"""## Splitting the dataset into the Training set and Test set"""

from sklearn.model_selection import train_test_split                        #spliting the data in train and test.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""## Training XGBoost on the Training set"""

from xgboost import XGBClassifier                           #training the XGBoost.
classifier = XGBClassifier()
classifier.fit(X_train, y_train)

"""## Making the Confusion Matrix"""

from sklearn.metrics import confusion_matrix, accuracy_score                #performence metrics.
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

"""## Applying k-Fold Cross Validation"""

from sklearn.model_selection import cross_val_score                     #applying cross validation to improve performance.
accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard Deviation: {:.2f} %".format(accuracies.std()*100))